{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install Biopython openai \"elasticsearch<8\" python-dotenv mistralai fireworks-ai sentence_transformers\n",
    "%pip install --upgrade pandas\n",
    "%pip install websocket-client wikipedia-api wikipedia\n",
    "%pip install --upgrade fireworks-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from fireworks.client import Fireworks\n",
    "import anthropic\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "import pickle\n",
    "import traceback\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "client_openai = OpenAI()\n",
    "client_fireworks = Fireworks()\n",
    "client_anthropic = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape_for_json(input_string):\n",
    "    escaped_string = json.dumps(input_string)\n",
    "    return escaped_string\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "#Suppress warnings about elasticsearch certificates\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "\n",
    "def run_elasticsearch_query(query, index=[\"pubmed\"]):\n",
    "    # Retrieve Elasticsearch details from environment variables\n",
    "    es_host = os.getenv('ELASTICSEARCH_HOST')\n",
    "    es_user = os.getenv('ELASTICSEARCH_USER')\n",
    "    es_password = os.getenv('ELASTICSEARCH_PASSWORD')\n",
    "\n",
    "    # Connect to Elasticsearch\n",
    "    es = Elasticsearch(\n",
    "        [es_host],\n",
    "        http_auth=(es_user, es_password),\n",
    "        verify_certs=False,  # This will ignore SSL certificate validation\n",
    "        timeout=120  # Set the timeout to 60 seconds (adjust as needed)\n",
    "    )\n",
    "\n",
    "    # Convert the query string to a dictionary\n",
    "    if isinstance(query, str) and not isinstance(query, dict):\n",
    "        query_dict = json.loads(query)\n",
    "    else:\n",
    "        query_dict = query\n",
    "\n",
    "    print(\"\\n running es query:\")\n",
    "    print(query_dict)\n",
    "    print(\"\\n\")\n",
    "    # Execute the query\n",
    "    response = es.search(query_dict, index=index)\n",
    "\n",
    "    # Process the response to extract the required information\n",
    "    results = []\n",
    "    if response['hits']['hits']:\n",
    "        for hit in response['hits']['hits']:\n",
    "            result = {\n",
    "                \"id\": \"http://www.ncbi.nlm.nih.gov/pubmed/\"+str(hit['_id']),\n",
    "                \"title\": hit['_source'].get('title', 'No title available'),\n",
    "                \"abstract\": hit['_source'].get('abstract', 'No abstract available')\n",
    "            }\n",
    "            results.append(result)\n",
    "    print(f\"docs found: {len(results)}\")\n",
    "    return results\n",
    "\n",
    "def createQuery(query_string: str, size=50): \n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"query_string\": {\n",
    "                \"query\": query_string\n",
    "            }\n",
    "        },\n",
    "        \"size\": size\n",
    "    }\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query_few_shot(df_prior, n, question:str, model:str):\n",
    "    messages = generate_n_shot_examples_expansion(df_prior, n)\n",
    "    # Add the user message\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "        Given a biomedical question, generate an Elasticsearch query string that incorporates synonyms and related terms to improve the search results while maintaining precision and relevance to the original question.\n",
    "\n",
    "        The index contains the fields 'title' and 'abstract', which use the English stemmer. The query string syntax supports the following operators:\n",
    "        - '+' and '-' for requiring or excluding terms (e.g., +fox -news)\n",
    "        - '\"\"' for phrase search (e.g., \"quick brown\")\n",
    "        - ':' for field-specific search (e.g., title:(quick OR brown))\n",
    "        - '*' or '?' for wildcards (e.g., qu?ck bro*)\n",
    "        - '//' for regular expressions (e.g., title:/joh?n(ath[oa]n)/)\n",
    "        - '~' for fuzzy matching (e.g., quikc~ or quikc~2)\n",
    "        - '\"...\"~N' for proximity search (e.g., \"fox quick\"~5)\n",
    "        - '^' for boosting terms (e.g., quick^2 fox)\n",
    "        - 'AND', 'OR', 'NOT' for boolean matching (e.g., ((quick AND fox) OR (brown AND fox) OR fox) AND NOT news)\n",
    "\n",
    "        Example:\n",
    "        Question: What are the effects of vitamin D deficiency on the human body?\n",
    "        Query string: ((\"vitamin d\" OR \"vitamin d3\" OR \"cholecalciferol\") AND (deficiency OR insufficiency OR \"low levels\")) AND (\"effects\" OR \"impact\" OR \"consequences\") AND (\"human body\" OR \"human health\")\n",
    "\n",
    "        Tips:\n",
    "        - Focus on the main concepts and entities in the question.\n",
    "        - Use synonyms and related terms to capture variations in terminology.\n",
    "        - Be cautious not to introduce irrelevant terms that may dilute the search results.\n",
    "        - Strike a balance between precision and recall based on the specificity of the question.\n",
    "\n",
    "        Please generate a query string for the following biomedical question and wrap the final query in ## tags:\n",
    "        '{question}'\n",
    "        \"\"\"\n",
    "    }\n",
    "    messages.append(user_message)\n",
    "    \n",
    "    print(\"Prompt Messages:\")\n",
    "    print(messages)\n",
    "    \n",
    "    if \"accounts\" in model:\n",
    "        completion = client_fireworks.chat.completions.create(\n",
    "            model=model,\n",
    "            messages =messages,\n",
    "            max_tokens = 4096,\n",
    "            prompt_truncate_len = 27000,\n",
    "            temperature=0.0 # randomness of completion\n",
    "        )\n",
    "        answer = completion.choices[0].message.content\n",
    "    elif \"claude\" in model:\n",
    "        system_message_content = messages.pop(0)['content']\n",
    "        completion = client_anthropic.messages.create(\n",
    "            model=model,\n",
    "            system=system_message_content,\n",
    "            messages=messages,\n",
    "            max_tokens=4096,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        answer = completion.content[0].text\n",
    "    else:\n",
    "        completion = client_openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.0, # randomness of completion\n",
    "            seed=90128538\n",
    "        )\n",
    "        answer = completion.choices[0].message.content\n",
    "    print(\"\\n Completion:\")\n",
    "    print(answer)\n",
    "    print(\"\\n\")\n",
    "    return answer\n",
    "\n",
    "def expand_query_wiki(wiki_context: str, question:str, model: str)-> str:\n",
    "    # Add the user message\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "        {wiki_context}\n",
    "        Answer this question: '{question}' \n",
    "        Think step by step and write an exhaustive answer explaining your reasoning\"\"\"\n",
    "    }\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"},\n",
    "        user_message\n",
    "    ]\n",
    "    print(\"\\nMessages Expand Query:\")\n",
    "    print(messages)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.0, # randomness of completion\n",
    "        logprobs=False,\n",
    "        seed=90128538\n",
    "    )\n",
    "    query = f\"\"\"\n",
    "        {{\n",
    "            \"query\": {{\n",
    "                \"more_like_this\" : {{\n",
    "                \"fields\" : [\"title\", \"abstract\"],\n",
    "                \"like\" : {escape_for_json(completion.choices[0].message.content)},\n",
    "                \"min_term_freq\" : 1,\n",
    "                \"min_doc_freq\": 1,\n",
    "                \"boost_terms\": 1\n",
    "                }}\n",
    "            }},\n",
    "        \"size\":100\n",
    "        }}\n",
    "    \"\"\"\n",
    "    return query\n",
    "\n",
    "def generate_n_shot_examples_expansion(df, n):\n",
    "    \n",
    "    # Initialize the system message\n",
    "    system_message = {\"role\": \"system\", \"content\": \"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"}\n",
    "    \n",
    "    # Initialize the list of messages with the system message\n",
    "    messages = [system_message]\n",
    "    \n",
    "    \n",
    "    if n< 1:\n",
    "        top_entries = pd.DataFrame()\n",
    "    else:\n",
    "        top_entries = df.sort_values(by='f1_score', ascending=False).head(n)\n",
    "    \n",
    "    # Loop through each of the top n entries and add the user and assistant messages\n",
    "    for _, row in top_entries.iterrows():\n",
    "        question = row['question_body']\n",
    "        completion = row['completion']\n",
    "        \n",
    "        # Replace problematic characters in question\n",
    "        question = question.replace(\"/\", \"\\\\\\\\/\")\n",
    "        \n",
    "        # Add the user message\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Given a biomedical question, generate an Elasticsearch query string that incorporates synonyms and related terms to improve the search results while maintaining precision and relevance to the original question.\n",
    "\n",
    "            The index contains the fields 'title' and 'abstract', which use the English stemmer. The query string syntax supports the following operators:\n",
    "            - '+' and '-' for requiring or excluding terms (e.g., +fox -news)\n",
    "            - '\"\"' for phrase search (e.g., \"quick brown\")\n",
    "            - ':' for field-specific search (e.g., title:(quick OR brown))\n",
    "            - '*' or '?' for wildcards (e.g., qu?ck bro*)\n",
    "            - '//' for regular expressions (e.g., title:/joh?n(ath[oa]n)/)\n",
    "            - '~' for fuzzy matching (e.g., quikc~ or quikc~2)\n",
    "            - '\"...\"~N' for proximity search (e.g., \"fox quick\"~5)\n",
    "            - '^' for boosting terms (e.g., quick^2 fox)\n",
    "            - 'AND', 'OR', 'NOT' for boolean matching (e.g., ((quick AND fox) OR (brown AND fox) OR fox) AND NOT news)\n",
    "\n",
    "            Example:\n",
    "            Question: What are the effects of vitamin D deficiency on the human body?\n",
    "            Query string: ((\"vitamin d\" OR \"vitamin d3\" OR \"cholecalciferol\") AND (deficiency OR insufficiency OR \"low levels\")) AND (\"effects\" OR \"impact\" OR \"consequences\") AND (\"human body\" OR \"human health\")\n",
    "\n",
    "            Tips:\n",
    "            - Focus on the main concepts and entities in the question.\n",
    "            - Use synonyms and related terms to capture variations in terminology.\n",
    "            - Be cautious not to introduce irrelevant terms that may dilute the search results.\n",
    "            - Strike a balance between precision and recall based on the specificity of the question.\n",
    "\n",
    "            Please generate a query string for the following biomedical question and wrap the final query in ## tags:\n",
    "            '{question}'\n",
    "            \"\"\"\n",
    "        }\n",
    "        \n",
    "        # Add the assistant message\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": completion  \n",
    "        }\n",
    "        \n",
    "        messages.extend([user_message, assistant_message])\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_query_with_no_results(question, original_query, model):\n",
    "    messages = [\n",
    "{\"role\": \"system\", \"content\": \"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"},\n",
    "{\"role\": \"user\", \"content\": f\"\"\"Given that the following search query has returned no documents, please generate a broader query that retains the original question's context and relevance. Return only the query that can directly be used without any explanation text. Focus on maintaining the query's precision and relevance to the original question.\n",
    "\n",
    "To generate a broader query, consider the following:\n",
    "\n",
    "Identify the main concepts in the original query and prioritize them based on their importance to the question.\n",
    "Simplify the query by removing less essential terms or concepts that might be too specific or restrictive.\n",
    "Use more general terms or synonyms for the main concepts to expand the search scope while maintaining relevance.\n",
    "Reduce the number of Boolean operators (AND, OR) to make the query less restrictive.\n",
    "If the original query includes specific drug names, genes, or proteins, consider using their classes or families instead.\n",
    "Avoid using too many search fields or specific phrases in quotes, as they can limit the search results.\n",
    "Original question: '{question}', Original query that returned no results: '{original_query}' think step by step an wrapp the improved query in ## tags:\"\"\"}\n",
    "]\n",
    "\n",
    "    print(\"Prompt Messages:\")\n",
    "    print(messages)\n",
    "    \n",
    "    if \"accounts\" in model:\n",
    "        completion = client_fireworks.chat.completions.create(\n",
    "            model=model,\n",
    "            messages =messages,\n",
    "            max_tokens = 4096,\n",
    "            prompt_truncate_len = 27000,\n",
    "            temperature=0.0 # randomness of completion\n",
    "        )\n",
    "        answer = completion.choices[0].message.content\n",
    "    elif \"claude\" in model:\n",
    "        system_message_content = messages.pop(0)['content']\n",
    "        completion = client_anthropic.messages.create(\n",
    "            model=model,\n",
    "            system=system_message_content,\n",
    "            messages=messages,\n",
    "            max_tokens=4096,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        answer = completion.content[0].text\n",
    "    else:\n",
    "        completion = client_openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.0, # randomness of completion\n",
    "            seed=90128538\n",
    "        )\n",
    "        answer = completion.choices[0].message.content\n",
    "    print(\"\\n Completion:\")\n",
    "    print(answer)\n",
    "    print(\"\\n\")\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snippet Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_extract_json(text):\n",
    "    pattern = r'\\{.*?\\}'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    match = matches[0]\n",
    "    match_clean = match.replace('\\\\', \"\\\\\\\\\")\n",
    "    match_clean = match_clean.replace('\\t', \"\\\\t\")\n",
    "    return match_clean\n",
    "\n",
    "from unicodedata import normalize\n",
    "def normalize_unicode_string(s, form='NFKC'):\n",
    "    normalized  = normalize('NFKD', s).encode('ascii','ignore').decode()\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def generate_n_shot_examples_extraction(examples, n):\n",
    "    \"\"\"Takes the top n examples, flattens their messages into one list, and filters out messages with the role 'system'.\"\"\"\n",
    "    n_shot_examples = []\n",
    "    for example in examples[:n]:\n",
    "        for message in example['messages']:\n",
    "            if message['role'] != 'system':  # Only add messages that don't have the 'system' role\n",
    "                n_shot_examples.append(message)\n",
    "    return n_shot_examples\n",
    "\n",
    "def extract_relevant_snippets_few_shot(examples, n, article:str, question:str, model:str) -> str:\n",
    "    \n",
    "    system_message = {\"role\": \"system\", \"content\": \"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"}\n",
    "    messages = [system_message]\n",
    "    few_shot_examples = generate_n_shot_examples_extraction(examples, n)\n",
    "    messages.extend(few_shot_examples)\n",
    "    user_message = {\"role\": \"user\", \"content\": f\"\"\"Given this question: '{question}' extract relevant sentences or longer snippets from the following article that help answer the question. \n",
    "If no relevant information is present, return an empty array. Return the extracted snippets as a json string array called 'snippets'. ```{article}```\"\"\"}\n",
    "    messages.append(user_message)\n",
    "    print(\"Prompt Messages:\")\n",
    "    print(messages)\n",
    "    \n",
    "    if \"accounts\" in model:\n",
    "        completion = client_fireworks.chat.completions.create(\n",
    "            model=model,\n",
    "            messages =messages,\n",
    "            max_tokens = 4096,\n",
    "            prompt_truncate_len = 27000,\n",
    "            temperature=0.0 # randomness of completion\n",
    "        )\n",
    "    elif \"claude\" in model:\n",
    "        system_message_content = messages.pop(0)['content']\n",
    "        completion = client_anthropic.messages.create(\n",
    "            model=model,\n",
    "            system=system_message_content,\n",
    "            messages=messages,\n",
    "            max_tokens=4096,\n",
    "            temperature=0.0\n",
    "        )\n",
    "    else:\n",
    "        completion = client_openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.0, # randomness of completion\n",
    "            response_format={ \"type\": \"json_object\" },\n",
    "            seed=90128538\n",
    "        )\n",
    "    print(\"\\n Completion:\")\n",
    "    print(completion)\n",
    "    print(\"\\n\")\n",
    "    if hasattr(completion, 'choices'):\n",
    "        json_response = find_extract_json(completion.choices[0].message.content)\n",
    "    else:\n",
    "        json_response = find_extract_json(completion.content[0].text)\n",
    "    try:\n",
    "        sentences = json.loads(json_response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response as json: {json_response}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        sentences = {\"snippets\": []}\n",
    "    \n",
    "    \n",
    "    snippets = generate_snippets_from_sentences(article, sentences['snippets'])\n",
    "    \n",
    "    return snippets\n",
    "\n",
    "def find_offset_and_create_snippet(document_id, text, sentence, section):\n",
    "    text = normalize_unicode_string(text)\n",
    "    sentence = normalize_unicode_string(sentence)\n",
    "    offset_begin = text.find(sentence)\n",
    "    offset_end = offset_begin + len(sentence)\n",
    "    return {\n",
    "        \"document\": document_id,\n",
    "        \"offsetInBeginSection\": offset_begin,\n",
    "        \"offsetInEndSection\": offset_end,\n",
    "        \"text\": sentence,\n",
    "        \"beginSection\": section,\n",
    "        \"endSection\": section\n",
    "    }\n",
    "\n",
    "def generate_snippets_from_sentences(article, sentences):\n",
    "    snippets = []\n",
    "\n",
    "    article_abstract = article.get('abstract') or ''  # This will use '' if 'abstract' is None or does not exist\n",
    "    article_abstract = normalize_unicode_string(article_abstract)\n",
    "    article_title = normalize_unicode_string(article.get('title'))\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence = normalize_unicode_string(sentence)\n",
    "        if sentence in article_title:\n",
    "            snippet = find_offset_and_create_snippet(article['id'], article['title'], sentence, \"title\")\n",
    "            snippets.append(snippet)\n",
    "        elif sentence in article_abstract:\n",
    "            snippet = find_offset_and_create_snippet(article['id'], article_abstract, sentence, \"abstract\")\n",
    "            snippets.append(snippet)\n",
    "        else:\n",
    "            print(\"\\nsentences not found in article: \"+sentence+\"\\n\")\n",
    "            print(article)\n",
    "\n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snippet Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_shot_examples_reranking(examples, n):\n",
    "    \"\"\"Takes the top n examples, flattens their messages into one list, and filters out messages with the role 'system'.\"\"\"\n",
    "    n_shot_examples = []\n",
    "    for example in examples[:n]:\n",
    "        for message in example['messages']:\n",
    "            if message['role'] != 'system':  # Only add messages that don't have the 'system' role\n",
    "                n_shot_examples.append(message)\n",
    "    return n_shot_examples\n",
    "\n",
    "def rerank_snippets(examples, n, snippets, question:str, model:str) -> str:\n",
    "    numbered_snippets = [{'id': idx, 'text': snippet['text']} for idx, snippet in enumerate(snippets)]\n",
    "    system_message = {\"role\": \"system\", \"content\": \"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"}\n",
    "    messages = [system_message]\n",
    "    few_shot_examples = generate_n_shot_examples_reranking(examples, n)\n",
    "    messages.extend(few_shot_examples)\n",
    "    user_message = {\"role\": \"user\", \"content\": f\"\"\"Given this question: '{question}' select the top 10 snippets that are most helpfull for answering this question from\n",
    "                    this list of snippets, rerank them by helpfullness: ```{numbered_snippets}``` return a json array of their ids called 'snippets'\"\"\"}\n",
    "    messages.append(user_message)\n",
    "    print(\"Prompt Messages:\")\n",
    "    print(messages)\n",
    "    \n",
    "    if \"accounts\" in model:\n",
    "        completion = client_fireworks.chat.completions.create(\n",
    "            model=model,\n",
    "            messages =messages,\n",
    "            max_tokens = 4096,\n",
    "            prompt_truncate_len = 27000,\n",
    "            temperature=0.0 # randomness of completion\n",
    "        )\n",
    "    elif \"claude\" in model:\n",
    "        system_message_content = messages.pop(0)['content']\n",
    "        completion = client_anthropic.messages.create(\n",
    "            model=model,\n",
    "            system=system_message_content,\n",
    "            messages=messages,\n",
    "            max_tokens=4096,\n",
    "            temperature=0.0\n",
    "        )\n",
    "    else:\n",
    "        completion = client_openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.0, # randomness of completion\n",
    "            response_format={ \"type\": \"json_object\" },\n",
    "            seed=90128538\n",
    "        )\n",
    "    print(\"\\n Completion:\")\n",
    "    print(completion)\n",
    "    print(\"\\n\")\n",
    "    if hasattr(completion, 'choices'):\n",
    "        json_response = find_extract_json(completion.choices[0].message.content)\n",
    "    else:\n",
    "        json_response = find_extract_json(completion.content[0].text)\n",
    "    \n",
    "    try:\n",
    "        snippets_reranked = json.loads(json_response)\n",
    "        snippets_idx = snippets_reranked['snippets']\n",
    "        filtered_array = [snippets[i] for i in snippets_idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing response as json: {json_response}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        filtered_array = snippets\n",
    "        \n",
    "    return filtered_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Claude Opus + 1 shot -> UR-IW-1\n",
    "#model_name = \"claude-3-opus-20240229\"\n",
    "#model_name_extract = \"claude-3-opus-20240229\"\n",
    "#model_name_rerank = \"claude-3-opus-20240229\"\n",
    "\n",
    "## Mixtral + 10 shot -> UR-IW-4\n",
    "#model_name = \"accounts/fireworks/models/mixtral-8x7b-instruct\"\n",
    "#model_name_extract = \"accounts/fireworks/models/mixtral-8x7b-instruct\"\n",
    "#model_name_rerank = \"accounts/fireworks/models/mixtral-8x7b-instruct\"\n",
    "\n",
    "## Mixtral fine-tuned + 10 shot -> UR-IW-2\n",
    "#model_name = \"accounts/fireworks/models/mixtral-8x7b-instruct\"\n",
    "#model_name_extract = \"accounts/samyateia-49f400/models/fa6580e58ba04e52b8a16b484d23bc14\"\n",
    "#model_name_rerank = \"accounts/samyateia-49f400/models/336b7d6963d64fe0bc0de7264b737ba8\"\n",
    "\n",
    "## GPT-3.5-turbo + 10 shot -> UR-IW-5\n",
    "#model_name = \"gpt-3.5-turbo-0125\"\n",
    "#model_name_extract = \"gpt-3.5-turbo-0125\"\n",
    "#model_name_rerank = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "## GPT-3.5-turbo fine-tuned + 1 shot -> UR-IW-3 \n",
    "model_name = \"gpt-3.5-turbo-0125\"\n",
    "model_name_extract = \"ft:gpt-3.5-turbo-0125:samy-ateia-software-engineering:02-snip-extraction:96ykjZyI\"\n",
    "model_name_rerank = \"ft:gpt-3.5-turbo-0125:samy-ateia-software-engineering:03-snip-rank:96ySMiaO\"\n",
    "\n",
    "n_shot = 1\n",
    "\n",
    "# Get the current timestamp in a sortable format\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "if '/' in model_name or ':' in model_name:\n",
    "    pickl_name = model_name.replace('/', '-').replace(':', '-')\n",
    "else:\n",
    "    pickl_name = model_name\n",
    "pickl_file = f'{pickl_name}-{n_shot}-shot.pkl'\n",
    "\n",
    "def save_state(data, file_path=pickl_file):\n",
    "    \"\"\"Save the current state to a pickle file.\"\"\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_state(file_path=pickl_file):\n",
    "    \"\"\"Load the state from a pickle file if it exists, otherwise return None.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "    except EOFError:  # Handles empty pickle file scenario\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def read_jsonl_file(file_path):\n",
    "    \"\"\"Reads a JSONL file and returns a list of examples.\"\"\"\n",
    "    examples = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            examples.append(json.loads(line))\n",
    "    return examples\n",
    "\n",
    "def extract_text_wrapped_in_tags(input_string):\n",
    "    pattern = \"##(.*?)##\"\n",
    "    match = re.search(pattern, input_string, re.DOTALL)  \n",
    "    if match:\n",
    "        # Remove line breaks from the matched string\n",
    "        extracted_text = match.group(1).replace('\\n', '')\n",
    "        return extracted_text\n",
    "    else:\n",
    "        return \"ERROR\"\n",
    "\n",
    "def reorder_articles_by_snippet_sequence(relevant_article_ids, snippets):\n",
    "    ordered_article_ids = []\n",
    "    mentioned_article_ids = set()\n",
    "\n",
    "    # Add article IDs in the order they appear in the snippets\n",
    "    for snippet in snippets:\n",
    "        document_id = snippet['document']\n",
    "        if document_id in relevant_article_ids and document_id not in mentioned_article_ids:\n",
    "            ordered_article_ids.append(document_id)\n",
    "            mentioned_article_ids.add(document_id)\n",
    "\n",
    "    # Add the remaining article IDs that weren't mentioned in snippets\n",
    "    for article_id in relevant_article_ids:\n",
    "        if article_id not in mentioned_article_ids:\n",
    "            ordered_article_ids.append(article_id)\n",
    "\n",
    "    return ordered_article_ids\n",
    "\n",
    "\n",
    "def get_relevant_snippets(examples, n, articles, question, model_name):\n",
    "    processed_articles = []\n",
    "    for article in articles:\n",
    "        snippets = extract_relevant_snippets_few_shot(examples, n, article, question, model_name)\n",
    "        if snippets:\n",
    "            article['snippets'] = snippets\n",
    "            processed_articles.append(article)\n",
    "    return processed_articles\n",
    "\n",
    "# Run specific few-shot configuration\n",
    "query_examples = pd.read_csv('2024-03-26_19-24-27_claude-3-opus-20240229_11B1-10-Shot_Retrieval.csv')\n",
    "\n",
    "snip_extract_examples_file = \"Snippet_Extraction_Examples.jsonl\"     \n",
    "snip_extract_examples = read_jsonl_file(snip_extract_examples_file)\n",
    "\n",
    "snip_rerank_examples_file = \"Snippet_Reranking_Examples.jsonl\"     \n",
    "snip_rerank_examples = read_jsonl_file(snip_rerank_examples_file)\n",
    "\n",
    "\n",
    "def process_question(question):\n",
    "    try:\n",
    "        query_string = \"\"\n",
    "        improved_query_string = \"\"\n",
    "        relevant_articles_ids = []\n",
    "        filtered_articles_ids = [] \n",
    "        reordered_articles_ids = []\n",
    "        relevant_snippets = []\n",
    "\n",
    "        question_id = question['id']\n",
    "        print(f\"Processing question {question_id}\")\n",
    "        wiki_context = \"\"\n",
    "\n",
    "        #0 query expansion\n",
    "        completion = expand_query_few_shot(query_examples, n_shot, question['body'], model_name)\n",
    "        query_string = extract_text_wrapped_in_tags(completion)\n",
    "        query = createQuery(query_string)\n",
    "\n",
    "        relevant_articles = run_elasticsearch_query(query)\n",
    "        if len(relevant_articles) == 0:\n",
    "            improved_query_completion = refine_query_with_no_results(question['body'], query_string, model_name)\n",
    "            improved_query_string = extract_text_wrapped_in_tags(improved_query_completion)\n",
    "            query = createQuery(improved_query_string)\n",
    "            relevant_articles = run_elasticsearch_query(query)\n",
    "            if len(relevant_articles) > 0:\n",
    "                print(\"query refinement worked\")\n",
    "            \n",
    "        relevant_articles_ids = [article['id'] for article in relevant_articles]\n",
    "        \n",
    "        #1 snippet extraction\n",
    "        filtered_articles = get_relevant_snippets(snip_extract_examples, n_shot, relevant_articles, question['body'], model_name_extract)\n",
    "        filtered_articles_ids = [article['id'] for article in filtered_articles]\n",
    "        relevant_snippets = [snippet for article in filtered_articles for snippet in article['snippets']]\n",
    "\n",
    "        #2 rerank snippets\n",
    "        reranked_snippets = rerank_snippets(snip_rerank_examples, n_shot, relevant_snippets, question['body'], model_name_rerank)\n",
    "        \n",
    "        reordered_articles_ids = reorder_articles_by_snippet_sequence(filtered_articles_ids, reranked_snippets)\n",
    "\n",
    "        return {\n",
    "            \"question_id\": question[\"id\"],\n",
    "            \"question_body\": question[\"body\"],\n",
    "            \"question_type\": question[\"type\"],\n",
    "            \"wiki_context\": wiki_context,\n",
    "            \"completion\": completion,\n",
    "            \"query\": query_string,\n",
    "            \"improved_query\": improved_query_string,\n",
    "            \"relevant_articles\": relevant_articles_ids,\n",
    "            \"filtered_articles\": filtered_articles_ids,\n",
    "            \"documents\": reordered_articles_ids,\n",
    "            \"snippets\": reranked_snippets\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question {question['id']}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            \"question_id\": question.get(\"id\", \"error\"),\n",
    "            \"question_body\": question.get(\"body\", \"error\"),\n",
    "            \"question_type\": question.get(\"type\", \"error\"),\n",
    "            \"query\": query_string or \"error\",\n",
    "            \"improved_query\": improved_query_string or \"error\",\n",
    "            \"relevant_articles\": relevant_articles_ids or [],\n",
    "            \"filtered_articles\": filtered_articles_ids or [],\n",
    "            \"documents\": reordered_articles_ids[:10] if reordered_articles_ids else [],\n",
    "            \"snippets\": relevant_snippets or []\n",
    "        }\n",
    "\n",
    "# Define columns\n",
    "columns = ['question_id', 'question_body', 'question_type', 'wiki_context', 'completion', 'query', 'improved_query', 'relevant_articles', 'filtered_articles', 'documents', 'snippets']\n",
    "\n",
    "# Initialize empty DataFrame\n",
    "questions_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Load the input file in JSON format\n",
    "input_file_name = 'BioASQ-task12bPhaseA-testset2.json'\n",
    "\n",
    "\n",
    "with open(input_file_name) as input_file:\n",
    "    data = json.loads(input_file.read())\n",
    "\n",
    "# Assuming 'load_state' returns a DataFrame or None\n",
    "saved_df = load_state(pickl_file)\n",
    "\n",
    "if saved_df is not None and not saved_df.empty:\n",
    "    processed_ids = set(saved_df['question_id'])  # Assuming 'question_id' is your identifier\n",
    "    questions_df = saved_df\n",
    "else:\n",
    "    processed_ids = set()\n",
    "\n",
    "# Assuming `data[\"questions\"]` is your list of questions to process\n",
    "# Filter out questions that have already been processed\n",
    "questions_to_process = [q for q in data[\"questions\"] if q[\"id\"] not in processed_ids]\n",
    "#questions_to_process = questions_to_process[:2]\n",
    "\n",
    "\n",
    "# Use ThreadPoolExecutor to process questions in parallel\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    # Dictionary to keep track of question futures\n",
    "    future_to_question = {executor.submit(process_question, q): q for q in questions_to_process}\n",
    "    \n",
    "    for future in as_completed(future_to_question):\n",
    "        question = future_to_question[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                # Append result to the DataFrame\n",
    "                result_df = pd.DataFrame([result])\n",
    "                questions_df = pd.concat([questions_df, result_df], ignore_index=True)\n",
    "                save_state(questions_df, pickl_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {question['id']}: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "\n",
    "# Prefix the output file name with the timestamp\n",
    "if '/' in model_name:\n",
    "    model_name_pretty = model_name.split(\"/\")[-1]\n",
    "else:\n",
    "    model_name_pretty = model_name\n",
    "output_file_name = f\"./Results/{timestamp}_{model_name_pretty}_2024AB2-UR-IW-3-{n_shot}-Shot.csv\"\n",
    "\n",
    "# Ensure the directory exists before saving\n",
    "os.makedirs(os.path.dirname(output_file_name), exist_ok=True)\n",
    "\n",
    "questions_df.to_csv(output_file_name, index=False)\n",
    "\n",
    "# After processing all questions and saving the final output:\n",
    "try:\n",
    "    # Check if the pickle file exists before attempting to delete it\n",
    "    if os.path.exists(pickl_file):\n",
    "        os.remove(pickl_file)\n",
    "        print(\"Intermediate state pickle file deleted successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting pickle file: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Run File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def csv_to_json(csv_filepath, json_filepath):\n",
    "    empty = 0\n",
    "    # Step 1: Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_filepath)\n",
    "    \n",
    "    # Transform the DataFrame into a list of dictionaries, one per question\n",
    "    questions_list = df.to_dict(orient='records')\n",
    "    \n",
    "    # Initialize the structure of the JSON file\n",
    "    json_structure = {\"questions\": []}\n",
    "    \n",
    "    # Step 2: Transform the DataFrame into the desired JSON structure\n",
    "    for item in questions_list:\n",
    "        # Adjusting exact_answer format based on question_type\n",
    "        if item[\"question_type\"] in [\"list\", \"factoid\"]:\n",
    "            exact_answer_format = [[]]  # For 'list' or 'factoid', it's a list of lists\n",
    "        else:\n",
    "            exact_answer_format = \"\"  # Default to an empty string\n",
    "            \n",
    "            \n",
    "        if len(eval(item[\"relevant_articles\"])) == 0:\n",
    "            empty = empty +1\n",
    "        #print(len(eval(item[\"relevant_articles\"])))\n",
    "        # Construct question_dict conditionally excluding 'exact_answer' for 'ideal' type\n",
    "        question_dict = {\n",
    "            \"documents\": eval(item[\"documents\"])[:10],\n",
    "            \"snippets\": eval(item[\"snippets\"])[:10],\n",
    "            \"body\": item[\"question_body\"],\n",
    "            \"type\": item[\"question_type\"],\n",
    "            \"id\": item[\"question_id\"],\n",
    "            \"ideal_answer\": \"\"\n",
    "        }\n",
    "        if item[\"question_type\"] != \"summary\":\n",
    "            question_dict[\"exact_answer\"] = exact_answer_format\n",
    "        \n",
    "        json_structure[\"questions\"].append(question_dict)\n",
    "    \n",
    "    # Step 3: Write the JSON structure to a file\n",
    "    with open(json_filepath, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(json_structure, json_file, ensure_ascii=False, indent=4)\n",
    "    print(empty)\n",
    "\n",
    "# Example usage\n",
    "csv_filepath = './Results/2024-04-10_16-06-49_gpt-3.5-turbo-0125_2024AB2-UR-IW-3-1-Shot.csv'  # Update this path to your actual CSV file path\n",
    "json_filepath = './Results/ur-iw-3.json'  # Update this path to where you want to save the JSON file\n",
    "csv_to_json(csv_filepath, json_filepath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
