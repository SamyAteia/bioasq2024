{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install Biopython openai \"elasticsearch<8\" python-dotenv mistralai fireworks-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "#Suppress warnings about elasticsearch certificates\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "\n",
    "def run_elasticsearch_query(query, index=[\"pubmed\", \"pubmed_update\"]):\n",
    "    # Retrieve Elasticsearch details from environment variables\n",
    "    es_host = os.getenv('ELASTICSEARCH_HOST')\n",
    "    es_user = os.getenv('ELASTICSEARCH_USER')\n",
    "    es_password = os.getenv('ELASTICSEARCH_PASSWORD')\n",
    "\n",
    "    # Connect to Elasticsearch\n",
    "    es = Elasticsearch(\n",
    "        [es_host],\n",
    "        http_auth=(es_user, es_password),\n",
    "        verify_certs=False,  # This will ignore SSL certificate validation\n",
    "        timeout=60\n",
    "    )\n",
    "\n",
    "    # Convert the query string to a dictionary\n",
    "    query_dict = json.loads(query)\n",
    "\n",
    "    # Execute the query\n",
    "    response = es.search(query_dict, index=index)\n",
    "\n",
    "    # Process the response to extract the required information\n",
    "    results = []\n",
    "    if response['hits']['hits']:\n",
    "        for hit in response['hits']['hits']:\n",
    "            result = {\n",
    "                \"id\": hit['_id'],\n",
    "                \"title\": hit['_source'].get('title', 'No title available'),\n",
    "                \"abstract\": hit['_source'].get('abstract', 'No abstract available')\n",
    "            }\n",
    "            results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import traceback\n",
    "import fireworks.client\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "fireworks_api_key = os.environ[\"FIREWORKS_API_KEY\"]\n",
    "\n",
    "#mistral_api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "\n",
    "#mistral_client = MistralClient(api_key=mistral_api_key)\n",
    "\n",
    "fireworks.client.api_key = fireworks_api_key\n",
    "\n",
    "def ask_mixtral(messages):\n",
    "    return fireworks.client.ChatCompletion.create(\n",
    "    model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "    stream=False,\n",
    "    n=1,\n",
    "    messages=messages,\n",
    "    stop=[\"<|im_start|>\",\"<|im_end|>\",\"<|endoftext|>\"],\n",
    "    top_p=1,\n",
    "    top_k=40,\n",
    "    presence_penalty=0,\n",
    "    frequency_penalty=0,\n",
    "    context_length_exceeded_behavior=\"truncate\",\n",
    "    temperature=0,\n",
    "    max_tokens=32768\n",
    "    )\n",
    "\n",
    "def expand_query(question:str, model:str) -> str:\n",
    "    if(model.startswith('mistral')):\n",
    "        return expand_query_mistral(question, model)\n",
    "    else:\n",
    "        return expand_query_openai(question, model)\n",
    "\n",
    "\n",
    "def expand_query_openai(question:str, model:str) -> str:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"},\n",
    "             {\"role\": \"user\", \"content\": f\"\"\"Turn the following biomedical question into an effective elasticsearch query using the query_string query type \n",
    "            by incorporating synonyms and additional terms that closely relate to the main topic and help reduce ambiguity. \n",
    "            Focus on maintaining the query's precision and relevance to the original question, the index contains the fields 'title' and 'abstract', return valid json: \n",
    "            'Is CircRNA produced by back splicing of exon, intron or both, forming exon or intron circRNA?'\"\"\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"\"\"\n",
    "            {\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                    \"query\": \"(CircRNA OR \\\"circular RNA\\\") \\\"back splicing\\\" exon OR intron\",\n",
    "                    \"fields\": [\n",
    "                        \"title^10\",\n",
    "                        \"abstract\"\n",
    "                    ],\n",
    "                    \"default_operator\": \"and\"\n",
    "                    }\n",
    "                },\n",
    "                \"size\": 50\n",
    "                }\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"Turn the following biomedical question into an effective elasticsearch query using the query_string query type \n",
    "            by incorporating synonyms and additional terms that closely relate to the main topic and help reduce ambiguity. \n",
    "            Focus on maintaining the query's precision and relevance to the original question, the index contains the fields 'title' and 'abstract', return valid json:\n",
    "            'Which factor is inhibited by Milvexian?'\"\"\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"\"\"\n",
    "             {\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                    \"query\": \"Milvexian inhibitor (factor OR XIa OR FXIa)\",\n",
    "                    \"fields\": [\n",
    "                        \"title^10\",\n",
    "                        \"abstract\"\n",
    "                    ],\n",
    "                    \"default_operator\": \"and\"\n",
    "                    }\n",
    "                },\n",
    "                \"size\": 50\n",
    "                }\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"Turn the following biomedical question into an effective elasticsearch query using the query_string query type \n",
    "            by incorporating synonyms and additional terms that closely relate to the main topic and help reduce ambiguity. \n",
    "            Focus on maintaining the query's precision and relevance to the original question, the index contains the fields 'title' and 'abstract', return valid json:\n",
    "             '{question}'\"\"\"},\n",
    "        ],\n",
    "        temperature=0.0, # randomness of completion\n",
    "        logprobs=False,\n",
    "        seed=90128538\n",
    "    )\n",
    "    print(completion)\n",
    "    return completion.choices[0].message.content\n",
    "    \n",
    "#query = expand_query_openai(\"Can losartan reduce brain atrophy in Alzheimer\\u0027s disease?\", \"gpt-3.5-turbo-0125\")\n",
    "#json.dumps(json.loads(query))\n",
    "\n",
    "\n",
    "\n",
    "def expand_query_mistral(question: str, model:str) -> str:\n",
    "\n",
    "    messages = [\n",
    "    {\"role\":\"system\", \"content\":\"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"},\n",
    "    {\"role\":\"user\", \"content\":\"\"\"\"\n",
    "             Turn this question into an effective elasticsearch query using the simple_query_string query type, return valid json: \n",
    "             'Is CircRNA produced by back splicing of exon, intron or both, forming exon or intron circRNA?'\n",
    "             response:\n",
    "             {\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                    \"must\": [\n",
    "                        {\n",
    "                        \"simple_query_string\": {\n",
    "                            \"query\": \"CircRNA back splicing exon intron circular RNA\",\n",
    "                            \"fields\": [\"title^10\", \"abstract\"],\n",
    "                            \"default_operator\": \"and\"\n",
    "                        }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"should\": [\n",
    "                        {\n",
    "                        \"match\": {\n",
    "                            \"title\": {\n",
    "                            \"query\": \"CircRNA\",\n",
    "                            \"boost\": 3\n",
    "                            }\n",
    "                        }\n",
    "                        },\n",
    "                        {\n",
    "                        \"match\": {\n",
    "                            \"abstract\": {\n",
    "                            \"query\": \"back splicing\",\n",
    "                            \"boost\": 2\n",
    "                            }\n",
    "                        }\n",
    "                        },\n",
    "                        {\n",
    "                        \"match_phrase\": {\n",
    "                            \"abstract\": {\n",
    "                            \"query\": \"exon intron circular RNA\",\n",
    "                            \"boost\": 2\n",
    "                            }\n",
    "                        }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"minimum_should_match\": 1\n",
    "                    }\n",
    "                },\n",
    "                \"size\": 100\n",
    "                }\n",
    "             Turn this question into an effective elasticsearch query using the simple_query_string query type, return valid json: \n",
    "             'Which factor is inhibited by Milvexian?'\n",
    "             response:\n",
    "             {\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [{\n",
    "                                \"simple_query_string\": {\n",
    "                                    \"query\": \"Milvexian inhibitor factor XIa FXIa\",\n",
    "                                    \"fields\": [\"title^10\", \"abstract\"],\n",
    "                                    \"default_operator\": \"and\"\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        \"should\": [{\n",
    "                                \"match\": {\n",
    "                                    \"title\": {\n",
    "                                        \"query\": \"Milvexian\",\n",
    "                                        \"boost\": 3\n",
    "                                    }\n",
    "                                }\n",
    "                            }, {\n",
    "                                \"match\": {\n",
    "                                    \"abstract\": {\n",
    "                                        \"query\": \"inhibitor\",\n",
    "                                        \"boost\": 2\n",
    "                                    }\n",
    "                                }\n",
    "                            }, {\n",
    "                                \"match\": {\n",
    "                                    \"abstract\": {\n",
    "                                        \"query\": \"factor XIa FXIa\",\n",
    "                                        \"boost\": 2\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                        \"minimum_should_match\": 1\n",
    "                    },\n",
    "                    \"size\": 100\n",
    "                }\n",
    "            }\n",
    "            Turn this question into an effective elasticsearch query using the simple_query_string query type, return valid json: '\"\"\"+question+\"' \\nresponse:\"}\n",
    "    ]\n",
    "\n",
    "    # No streaming\n",
    "    chat_response = ask_mixtral(messages)\n",
    "    return extract_json_response(chat_response)\n",
    "\n",
    "def extract_json_response(chat_completion_response):\n",
    "    # Check if the response is in the expected format\n",
    "    if not hasattr(chat_completion_response, 'choices') or not chat_completion_response.choices:\n",
    "        return \"Invalid chat completion response format.\"\n",
    "\n",
    "    # Extract the content from the first choice in the response\n",
    "    content = chat_completion_response.choices[0].message.content\n",
    "    print(content)\n",
    "\n",
    "    # Regular expression to extract JSON object\n",
    "    json_pattern = r\"\\{.*\\}\"\n",
    "\n",
    "    # Search for the JSON pattern in the content\n",
    "    match = re.search(json_pattern, content, re.DOTALL)\n",
    "\n",
    "    if not match:\n",
    "        return \"No valid JSON object found in the content.\"\n",
    "\n",
    "    # Extract the JSON string\n",
    "    json_string = match.group()\n",
    "\n",
    "    corrected_json_string = json_string.replace(\"\\\\\\\\\", \"\\\\\").replace(\"\\_\", \"_\")\n",
    "\n",
    "    print(\"corrected string:\"+corrected_json_string)\n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        json.loads(corrected_json_string)\n",
    "        return corrected_json_string\n",
    "    except Exception as e:\n",
    "        print(\"Error with corrected json string:\")\n",
    "        print(corrected_json_string)\n",
    "        traceback.print_exc()\n",
    "        return f\"Error decoding JSON: {e}\"\n",
    "\"\"\"\n",
    "# Example usage\n",
    "question = \" Provide a list of compounds with well-characterized senomorphic activity.\"\n",
    "model = \"mistral-small\"  # Replace with the actual model name\n",
    "result = expand_query_mistral(question, model)\n",
    "print(result)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snippet Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relevant_snippets(article:str, question:str, model:str) -> str:\n",
    "    if(model.startswith('mistral')):\n",
    "        return extract_relevant_snippets_mistral(article, question, model)\n",
    "    else:\n",
    "        return extract_relevant_snippets_openai(article, question, model)\n",
    "\n",
    "\n",
    "\n",
    "def extract_relevant_snippets_openai(article, question, model):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"Given this question: '{question}' extract relevant sentences or longer snippets from the following article that help answer the question. \n",
    "             If no relevant information is present, return an empty array. Return the extracted snippets as a json string array called 'snippets'. ```{article}```\"\"\"}\n",
    "        ],\n",
    "        temperature=0.0, # randomness of completion\n",
    "        logprobs=False,\n",
    "        seed=90128538\n",
    "    )\n",
    "    print(completion)\n",
    "    sentences = json.loads(completion.choices[0].message.content)\n",
    "    snippets = generate_snippets_from_sentences(article, sentences['snippets'])\n",
    "    return snippets\n",
    "\n",
    "def extract_relevant_snippets_mistral(article, question, model):\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":\"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"},\n",
    "        {\"role\":\"user\", \"content\":f\"\"\"Given this question: '{question}' extract relevant sentences from the following article that help answer the question. \n",
    "             If no relevant information is present, return an empty array. Return the extracted sentences as a valid json object containing a json string array called 'sentences'. \n",
    "         Example: {{\"sentences\":[\"sentence1\", \"sentence2\"]}}```{article}```\"\"\"}\n",
    "    ]\n",
    "\n",
    "    print(\"\\nchat question:\")\n",
    "    print(messages)\n",
    "    print(\"\\n\")\n",
    "    snippets = []\n",
    "    try:\n",
    "        chat_response = ask_mixtral(messages)\n",
    "\n",
    "        print(\"chat response extract snippets:\")\n",
    "        print(chat_response)\n",
    "        chat_response_json = extract_json_response(chat_response)\n",
    "        sentences = json.loads(chat_response_json)\n",
    "        print(\"sentences extract snippets:\")\n",
    "        print(sentences)\n",
    "        snippets = generate_snippets_from_sentences(article, sentences['sentences'])\n",
    "    except Exception as e:\n",
    "        print(\"Error while extracting snippets\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    return snippets\n",
    "\n",
    "\n",
    "def find_offset_and_create_snippet(document_id, text, sentence, section):\n",
    "    offset_begin = text.find(sentence)\n",
    "    offset_end = offset_begin + len(sentence)\n",
    "    return {\n",
    "        \"document\": document_id,\n",
    "        \"offsetInBeginSection\": offset_begin,\n",
    "        \"offsetInEndSection\": offset_end,\n",
    "        \"text\": sentence,\n",
    "        \"beginSection\": section,\n",
    "        \"endSection\": section\n",
    "    }\n",
    "\n",
    "def generate_snippets_from_sentences(article, sentences):\n",
    "    snippets = []\n",
    "\n",
    "    article_abstract = article.get('abstract') or ''  # This will use '' if 'abstract' is None or does not exist\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence in article['title']:\n",
    "            snippet = find_offset_and_create_snippet(article['id'], article['title'], sentence, \"title\")\n",
    "            snippets.append(snippet)\n",
    "        elif sentence in article_abstract:\n",
    "            snippet = find_offset_and_create_snippet(article['id'], article_abstract, sentence, \"abstract\")\n",
    "            snippets.append(snippet)\n",
    "\n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_snippets(snippets:str, question:str, model:str) -> str:\n",
    "    if len(snippets) == 0:\n",
    "        return []\n",
    "    if(model.startswith('mistral')):\n",
    "        return select_top_snippets_mistral(snippets, question, model)\n",
    "    else:\n",
    "        return select_top_snippets_openai(snippets, question, model)\n",
    "\n",
    "\n",
    "def select_top_snippets_openai(snippets, question, model):\n",
    "    numbered_snippets = [{'id': idx, 'text': snippet['text']} for idx, snippet in enumerate(snippets)]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"Given this question: '{question}' select the top 10 snippets that are most helpfull for answering this question from\n",
    "             this list of snippets, rerank them by helpfullness: ```{numbered_snippets}``` return a json array of their ids called 'snippets'\"\"\"}\n",
    "        ],\n",
    "        temperature=0.0, # randomness of completion\n",
    "        logprobs=False,\n",
    "        seed=90128538\n",
    "    )\n",
    "    print(completion)\n",
    "    snippets_idx = json.loads(completion.choices[0].message.content)['snippets']\n",
    "    filtered_array = [snippets[i] for i in snippets_idx]\n",
    "\n",
    "    return filtered_array\n",
    "    \n",
    "def select_top_snippets_mistral(snippets, question, model):\n",
    "    numbered_snippets = [{'id': idx, 'text': snippet['text']} for idx, snippet in enumerate(snippets)]\n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":\"You are BioASQ-GPT, an AI expert in question answering, research, and information retrieval in the biomedical domain.\"},\n",
    "        {\"role\":\"user\", \"content\":f\"\"\"Given this question: '{question}' select the top 10 snippets that are most helpfull for answering this question from\n",
    "            this list of snippets, rerank them by helpfullness: ```{numbered_snippets}``` return a json array of their ids called 'snippets'\"\"\"}\n",
    "    ]\n",
    "\n",
    "    chat_response = ask_mixtral(messages)\n",
    "\n",
    "    print(\"chat response select snippets:\")\n",
    "    print(chat_response)\n",
    "    print(\"snippets idx:\")\n",
    "    snippets_idx = json.loads(chat_response.choices[0].message.content)['snippets']\n",
    "    print(snippets_idx)\n",
    "    filtered_array = [snippets[i] for i in snippets_idx]\n",
    "\n",
    "    return filtered_array\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synergy Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import traceback\n",
    "import pickle\n",
    "\n",
    "\n",
    "model_name = \"gpt-3.5-turbo-0125\"\n",
    "#model_name = \"gpt-4-0125-preview\"\n",
    "#model_name = \"mistral-small\"\n",
    "\n",
    "def append_to_logfile(logfile_name, text):\n",
    "    with open(logfile_name, 'a', encoding='utf-8') as logfile:\n",
    "        logfile.write(text + \"\\n\")\n",
    "\n",
    "# Get the current timestamp in a sortable format\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "logfile_name = f\"{timestamp}_{model_name}_PhaseA_No_Expansion_log_file.json\"\n",
    "debug_logfile = f\"{timestamp}_{model_name}_PhaseA_No_Expansion_Debug_log_file.json\"\n",
    "\n",
    "def reorder_articles_by_snippet_sequence(relevant_article_ids, snippets):\n",
    "    ordered_article_ids = []\n",
    "    mentioned_article_ids = set()\n",
    "\n",
    "    # Add article IDs in the order they appear in the snippets\n",
    "    for snippet in snippets:\n",
    "        document_id = snippet['document']\n",
    "        if document_id in relevant_article_ids and document_id not in mentioned_article_ids:\n",
    "            ordered_article_ids.append(document_id)\n",
    "            mentioned_article_ids.add(document_id)\n",
    "\n",
    "    # Add the remaining article IDs that weren't mentioned in snippets\n",
    "    for article_id in relevant_article_ids:\n",
    "        if article_id not in mentioned_article_ids:\n",
    "            ordered_article_ids.append(article_id)\n",
    "\n",
    "    return ordered_article_ids\n",
    "\n",
    "def get_relevant_articles_and_snippets(question_id, question, exclude_documents_by_question):\n",
    "    # stub function for getting relevant articles\n",
    "    print(\"Question: \"+question)\n",
    "    append_to_logfile(debug_logfile, f\"{{\\\"question\\\":\\\"{question}\\\",\")\n",
    "    query = expand_query(question, model_name)\n",
    "    append_to_logfile(debug_logfile, f\"\\\"query\\\":\\\"{query}\\\"\")\n",
    "    relevant_articles = run_elasticsearch_query(query)\n",
    "    print(\"number of relevant articles before filter:\") \n",
    "    print(len(relevant_articles))\n",
    "    exclude_documents = exclude_documents_by_question.get(question_id, set())\n",
    "    filtered_articles = [article for article in relevant_articles if article['id'] not in exclude_documents]\n",
    "    print(\"number of relevant articles after filter:\")\n",
    "    print(len(filtered_articles))\n",
    "\n",
    "\n",
    "    filtered_articles = get_relevant_snippets(filtered_articles[:50], question)\n",
    "\n",
    "    return filtered_articles\n",
    "\n",
    "def read_feedback_file(feedback_file_path):\n",
    "    with open(feedback_file_path, 'r') as file:\n",
    "        feedback_data = json.load(file)\n",
    "    \n",
    "    exclude_documents_by_question = {}\n",
    "    for question in feedback_data['questions']:\n",
    "        question_id = question['id']\n",
    "        exclude_documents = set()\n",
    "        for document in question['documents']:\n",
    "            exclude_documents.add(document['id'])\n",
    "        exclude_documents_by_question[question_id] = exclude_documents\n",
    "    \n",
    "    return exclude_documents_by_question\n",
    "\n",
    "\n",
    "def get_relevant_snippets(articles, question):\n",
    "    processed_articles = []\n",
    "\n",
    "    for article in articles:\n",
    "        snippets = extract_relevant_snippets(article, question, model_name)\n",
    "        if snippets:\n",
    "            article['snippets'] = snippets\n",
    "            processed_articles.append(article)\n",
    "\n",
    "    return processed_articles\n",
    "\n",
    "\n",
    "\n",
    "def save_state(data, file_path='state.pkl'):\n",
    "    \"\"\"Save the current state to a pickle file.\"\"\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_state(file_path='state.pkl'):\n",
    "    \"\"\"Load the state from a pickle file if it exists, otherwise return None.\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "    except EOFError:  # Handles empty pickle file scenario\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "# Read excluded document IDs from the feedback file\n",
    "exclude_documents_by_question = read_feedback_file(\"./Round4/BioASQ-taskSynergy_2024-feedback_round4.json\")\n",
    "\n",
    "# Load the input file in JSON format\n",
    "input_file_name = './Round4/BioASQ-taskSynergy_v2024-testset4.json'\n",
    "#input_file_name = './test_queries'\n",
    "with open(input_file_name) as input_file:\n",
    "    data = json.loads(input_file.read())\n",
    "\n",
    "# Try to load the saved state\n",
    "saved_state = load_state()\n",
    "if saved_state:\n",
    "    results = saved_state\n",
    "    offset = len(results)  # Determine where to continue processing\n",
    "else:\n",
    "    results = []\n",
    "    offset = 0\n",
    "\n",
    "for idx, question in enumerate(data[\"questions\"]):\n",
    "    print(idx)\n",
    "    if idx < offset:\n",
    "        continue\n",
    "\n",
    "    retry_count = 0  # Initialize a counter for retries\n",
    "    while retry_count < 2:  # Set the maximum number of retries to 2\n",
    "        try:\n",
    "            # Call the stub function to get relevant articles\n",
    "            print(\"processing question \"+str(idx))\n",
    "            print(question)\n",
    "            relevant_articles = get_relevant_articles_and_snippets(question[\"id\"], question['body'], exclude_documents_by_question)\n",
    "            relevant_articles_ids = [article['id'] for article in relevant_articles]\n",
    "            relevant_snippets = [snippet for article in relevant_articles for snippet in article['snippets']]\n",
    "            relevant_snippets = select_top_snippets(relevant_snippets,question,model_name)\n",
    "            relevant_articles_ids = reorder_articles_by_snippet_sequence(relevant_articles_ids, relevant_snippets)\n",
    "\n",
    "            # Create a dictionary to store the results for this question\n",
    "            question_results = {\n",
    "                \"body\": question[\"body\"],\n",
    "                \"id\": question[\"id\"],\n",
    "                \"type\": question[\"type\"],\n",
    "                \"documents\": relevant_articles_ids[:10],\n",
    "                \"snippets\": relevant_snippets\n",
    "            }\n",
    "\n",
    "\n",
    "            # Add the results for this question to the list of all results\n",
    "            results.append(question_results)\n",
    "            save_state(results)\n",
    "\n",
    "            break  # If no exception is thrown, break the loop\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {idx}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            retry_count += 1  # Increment the retry counter\n",
    "            time.sleep(5)  # Sleep for 5 seconds before retrying\n",
    "\n",
    "# Create a dictionary to store the results for all questions\n",
    "output = {\n",
    "    \"questions\": results\n",
    "}\n",
    "\n",
    "# Prefix the output file name with the timestamp\n",
    "output_file_name = f\"./Round4/Result/{timestamp}_{model_name}_missing_Synergy_output_file.json\"\n",
    "\n",
    "# Ensure the directory exists before saving\n",
    "os.makedirs(os.path.dirname(output_file_name), exist_ok=True)\n",
    "\n",
    "# Save the output to a file in pretty-formatted JSON format\n",
    "with open(output_file_name, \"w\") as f:\n",
    "    json.dump(output, f, indent=4)\n",
    "\n",
    "# After processing all questions and saving the final output:\n",
    "try:\n",
    "    # Check if the pickle file exists before attempting to delete it\n",
    "    if os.path.exists('state.pkl'):\n",
    "        os.remove('state.pkl')\n",
    "        print(\"Intermediate state pickle file deleted successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting pickle file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
